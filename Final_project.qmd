---
title: "Introduction to Data Science: Fall 2022 Final Project"
subtitle: "Predicting crop yields in the United States with weather data, using supervised machine learning."
author: Alexa Beeson, Mia Minkin, Hailey Wellenstein, and Zujaja Baig
format: html
editor: visual
editor_options: 
  chunk_output_type: console
execute: 
  warning: false
self-contained: true
theme: cosmo
code-fold: true
---
# Using Climate Data to Predict Corn Production Across the United States

## *Introduction*

A crop's performance in the field is a product of the environment in which it is grown. Of course, there are many factors that impact the environment in the field that are as niche as soil pH and as impactful as drought. Some factors include humidity, average precipitation, soil type, soil nutrients, days of sunshine, temperature, wind, and natural disasters. There are also technologies that impact crop production such as irrigation, fertilization, genetically modified seeds, and pesticides. These factors are quickly changing across the United States as climate change continues to impact where and how well certain crops can be successfully grown. Farmers also have to adapt to new or revised technologies to keep up with the ever-changing field environment, which is more often than not out of their control. In this project, we wanted to leverage information about these factors and technologies to predict crop production across the United States. However, it is very challenging to come across data on all these measures consistently across the United States at the same level of observation. We use limited data- just two measures of environment, air quality and drought- to create a supervised machine learning model that predicts yearly corn production in all counties with such information available. We believe that this absence of uniform and breadth of data actually makes our predictive model more "realistic" to farmers with the same kinds of limitations on data collection as we had. While there are some states that are more heavily engaged in corn production, such as Iowa and Illinois, we wanted to deepen our dataset to include all the counties we could that grow corn across the United States. By broadening our model to include counties from nearly all states, we also have more variation in our predictor variables- as droughts and air quality vary widely across the United States. More information on how we retrieved and merged this data are in sections to follow.

## *Data*
Loading in packages
```{r}
#Packages
library(tidyverse)
library(stringr)
library(readr)
library(tigris)
library(tidymodels)
library(yardstick)
library(ggridges)
library(RColorBrewer)
library(usmap)
library(tidycensus)
library(datasets)
library(patchwork)
library(vip)
```
**Data Sets**
To create a simple supervised machine learning model to predict corn production across the United States, we needed data that was available across the United States and publicly accessible. We needed to ensure there would be enough observations the sufficiently feed our model. We also needed to ensure that the environmental or climate measures we used had suitable variation and also were different enough measures that they were not repeating information. These factors combined are how we decided upon using air quality metrics and a drought index to predict corn production in bushels at the county level. Air Quality dataset came from the United States Environmental Protection Agency (EPA). Available as a [.csv file](https://aqs.epa.gov/aqsweb/airdata/download_files.html) (annual_aqi_by_county_2017), this publicly available dataset was easily downloadable from the EPA website. It contains several measures of air health- notably the Air Quality Index (AQI). The AQI is an index scaled from 0-500 that measures overall air quality, with lower values representing better air quality. It also holds data on days with common pollutants that have strong negative impacts on general air quality- days with carbon monoxide, nitrogen dioxide, or ozone detection. It also includes information on days with pollutant particles in the air, a measure called "PM".

Drought data came from the University of Nebraska- Lincoln. On the UNL website, it is possible to customize datasets from multiple selection criteria. We used the Drought Severity and Coverage Index (DSCI) data, available for public download as a [.csv file](https://droughtmonitor.unl.edu/DmData/DataDownload/DSCI.aspx). We decided to use two years of data for this measure- as we believe the prevalence of severe drought in 2016 will impact the crop growth of 2017. We downloaded two separate files for each year, selecting all available counties, and then edited the data set to create an average DSCI measure for each county each year. The DSCI is also an index measured from 0-500 with lower values representing no drought, and higher values representing extreme drought.

Finally, the corn production dataset is one we created ourselves from information on the United States Department of Agriculture's (USDA) 2017 Census of Agriculture. This census collects information on all farms and the people who own and operate them. The USDA believes this sentence serves as the voice for America's farmers and ranchers. We believe using information like this is not only an interesting exercise in predictive modeling, but also helps demonstrate the impact climate change has on the land and on the livelihoods of those who work it. To retrieve the USDA Census data, we used an application programming interface (API) to select and download the tables we needed in each state. The USDA Census of Agriculture has a web-based API that allows url edits to retrieve PDF versions of corn production tables. We used this API manipulation to call tables for all the states we used in this project.

Using Alabama as an example: <https://www.nass.usda.gov/Publications/AgCensus/2017/Full_Report/Volume_1,_Chapter_2_County_Level/Alabama/st01_2_0025_0025.pdf>

Volume and Chapter allowed us to select a portion of the Census to narrow down the available tables. Level allowed us to find data on the county level- as it is available nationally, by state, and by county. Then we could change the state through calling its direct name as well as altering the FIPS code that follows "st". Finally, the final digits call up a specific table- field crop production. After downloading each state as an individual .pdf, we merged the data sets to allow the unit of observation to exist on the county level.

*Reading in data*
Yield data:
```{r}
#yield data: corn yield data from United States Department of Agriculture
corn_yield<-read_csv("corn_yield.csv")

corn_yield$state_code<-corn_yield$State 
corn_yield$County<-str_replace(corn_yield$County,"St ","St.") 
corn_yield$state_county<-paste(corn_yield$state_code,corn_yield$County,sep=",")
corn_harvested<-corn_yield[-c(3,4)]
```
Air quality data:
```{r}
#air quality data: air quality data for 2017 from Environmental Protection Agency
air_quality<-read_csv("corn_counties_aq.csv")

air_quality<-air_quality%>%
             mutate(state_code=State) 
x<-air_quality$state_code
state_abbreviations<-state.abb[match(x,state.name)]
air_quality$state_code<-c(state_abbreviations)
air_quality$County<-str_replace(air_quality$County,"Saint","St.") 
air_quality$state_county<-paste(air_quality$state_code,air_quality$County,sep=",")
```
Drought data:
```{r}
#drought data 2017: From University of Nebraska Lincoln
drought<-read_csv("drought_means.csv")

drought<-drought[-c(1)] %>%
  rename(meanDSCI2017 = "meanDSCI")

county_names<-str_remove(drought$County,"County")
drought$County <-str_remove(drought$County, "County")
county_names<-str_remove(drought$County,"Parish")
drought$County<-c(county_names)
drought$County<-str_replace(drought$County,"Saint","St.")
#adding state + county
drought$state_county<-paste(drought$State,drought$County,sep=",")
drought$state_county<-trimws(drought$state_county)

#drought data 2016: From University of Nebraska Lincoln
drought_2016 <- read.csv("dm_export_20160101_20161231.csv")

drought_2016_average <- drought_2016 %>%
  group_by(State, County) %>%
  summarise(mean(DSCI)) %>%
  rename(meanDSCI2016 = "mean(DSCI)")

county_names<-str_remove(drought_2016_average$County,"County")
drought_2016_average$County <-str_remove(drought_2016_average$County, "County")
county_names<-str_remove(drought_2016_average$County,"Parish")
drought_2016_average$County <-str_remove(drought_2016_average$County, "Parish")
county_names<-str_remove(drought_2016_average$County,"Borough")
drought_2016_average$County <-str_remove(drought_2016_average$County, "Borough")
county_names<-str_remove(drought_2016_average$County,"Census Area")
drought_2016_average$County <-str_remove(drought_2016_average$County, "Census Area")

#adding state + county
drought_2016_average$state_county<-paste(drought_2016_average$State,drought_2016_average$County,sep=",")
drought_2016_average$state_county<-trimws(drought_2016_average$state_county)
```

**Merging the Data**
Because we used data from multiple sources, one of the most time-heavy aspects of this project was ensuring we merged the data in the right manner. All of the data was already on the county level, but due to differences in naming conventions across the United States (counties are called "Parishes" in Louisiana and there are some states that use "Census Area" or "Borough" instead of county) we had to make sure to clean the names of individual data sets before merging them. First, we joined the air quality data set with the corn production data set, dropping the counties for which there was either no corn or air quality data. We then joined the drought data set, and finally we added in the geography data- including FIPS codes and latitude/longitude in order to create geo-spatial visualizations in our exploratory data analysis portion of this project.

Joining Modeling Data
```{r}
#Joining model data 

air_and_corn<-left_join(air_quality,corn_harvested,by="state_county")
air_and_corn<-air_and_corn%>%
              rename("State"="State.x",
                     "County"="County.x",
                     "Quantity_Harvested"="Quantity Harvested")%>%
             relocate(state_county,.after=County)%>%
             relocate(Quantity_Harvested,.after=state_county)
#Some had corn data for fields harvested, but did not have an associated quantity, we omit these values
air_and_corn<-na.omit(air_and_corn)

#Joining drought data with air and corn
air_corn_drought<-left_join(air_and_corn,drought,by="state_county") 
air_corn_drought <- left_join(air_corn_drought,drought_2016_average,by="state_county")

#Cleaning up results of join
air_corn_drought <- air_corn_drought %>%
  select(-c("County.y.y", "State.y.y", "state_code.y","County.y","State.y","state_code.x", "State", "County"))%>%
  rename(state=State.x)%>%
  rename(county=County.x)%>%
  filter(!is.na(meanDSCI2016)) %>%
  mutate(log_quantityharvested = log(Quantity_Harvested, base = 10))

```
Joining geographic data
```{r}
#| output: false
#FIPS Code
FIPS_CODES<-data("fips_codes")

fips_codes$state_county<-paste(fips_codes$state,fips_codes$county,sep=",")
fips_codes$code<-paste(fips_codes$state_code,fips_codes$county_code)
fips_codes$state_county<-str_remove(fips_codes$state_county,"County")
fips_codes$state_county<-trimws(fips_codes$state_county)

#County geographies
counties<-counties()
counties$code<-paste(counties$STATEFP,counties$COUNTYFP)

#Joining
air_corn_drought_gps<-left_join(air_corn_drought,fips_codes,by="state_county") #merging in fips codes
air_corn_drought_gps<-left_join(air_corn_drought_gps,counties,by="code") #merging in geometries

#Cleaning up results of join
air_corn_drought_gps <- air_corn_drought_gps %>%
  select(-c("NAMELSAD", "NAME", "county.y", "COUNTYFP", "STATEFP", "state_name", "state.y"))%>%
  rename(state = state.x)%>%
  rename(county = county.x)%>%
  relocate(c("state", "county", "state_county", "state_code", "county_code", "code"))

#adding drought categories
air_corn_drought_gps <- air_corn_drought_gps %>%
  mutate(drought_category2017 = case_when(
          meanDSCI2017 <= 99 ~ "None",
          meanDSCI2017 >=100 & meanDSCI2017 <= 199 ~ "D0",
         meanDSCI2017 >=200 & meanDSCI2017 <= 299 ~ "D1",
         meanDSCI2017 >=300 & meanDSCI2017 <= 399 ~ "D2",
         meanDSCI2017 >=400 & meanDSCI2017 <= 499 ~ "D3",
         meanDSCI2017 == 500 ~ "D4")) %>%
    mutate(drought_category2016 = case_when(
          meanDSCI2016 <= 99 ~ "None",
          meanDSCI2016 >=100 & meanDSCI2016 <= 199 ~ "D0",
         meanDSCI2016 >=200 & meanDSCI2016 <= 299 ~ "D1",
         meanDSCI2016 >=300 & meanDSCI2016 <= 399 ~ "D2",
         meanDSCI2016 >=400 & meanDSCI2016 <= 499 ~ "D3",
         meanDSCI2016 == 500 ~ "D4"))

```

## *Pre-Modeling Visualizations*
```{r}
#top 10 corn producing states lollipop chart
corn_plot <- air_corn_drought_gps %>%
  group_by(state) %>%
  summarize(corn_total = sum(Quantity_Harvested))%>%
   arrange(desc(corn_total)) %>%
  slice(1:10)
 
my_factor_levels <- c("Iowa", "Illinois", "Indiana", "Minnesota", "Ohio","Wisconsin","Michigan","Nebraska","South Dakota","Pennsylvania")

corn_plot$state <- factor(corn_plot$state, levels = my_factor_levels)

corn_plot <- corn_plot%>%
  ggplot() +
  geom_segment(mapping = aes(x=fct_rev(state), xend=state, y=0, yend=corn_total), color="grey", linewidth = 1, alpha = .6)+
  geom_point(mapping = aes(x = fct_rev(state), y = corn_total), color="#919151", size=4) +
  coord_flip()+
  theme_minimal() +
  scale_y_continuous(labels = scales::number_format(accuracy = 1000000))+
  labs(
    title = "What are the top 10 corn producing states in our sample?",
    subtitle = "Plot shows corn production quantities for the year 2017 in bushels for the\n top 10 corn producing states in our sample.",
    y = "Bushels of Corn Produced",
    x = NULL,
    caption = "Data Source:\nUnited States Department of Agriculture, 2017 Census"
  )+
  theme(plot.title = element_text(face="bold"))
  





#drought dispersion within states for 2017 histogram
air_corn_drought_gps$drought_category2017 <- factor(air_corn_drought_gps$drought_category2017, levels = c("None", "D0", "D1", "D2", "D3", "D4"))

air_corn_drought_gps$drought_category2016 <- factor(air_corn_drought_gps$drought_category2016, levels = c("None", "D0", "D1", "D2", "D3", "D4"))

drought_plot <- air_corn_drought_gps %>%
  ggplot()+
  geom_histogram(aes(x = meanDSCI2017, fill = drought_category2017), binwidth = 5, color = "white", alpha = .7) +
  geom_vline(xintercept = 100, linewidth = .2)+
  annotate("text", x = 140, y = 50, label = "Drought threshold", size = 3)+
  scale_fill_manual(values = c("#5B8A07", "#FFCB00", "#D65B00"), name = "Drought Category",
                    labels = c("No Drought", "Moderate Drought (D1)", "Severe Drought (D2)"))+
  theme_minimal() +
  labs(title = "What is the frequency of drought within our sample?",
       subtitle = "Plot shows the average score of drought severity for counties within each state of our sample\n for the year 2017. Drought categories are derived from Drought Severity and Coverage Index\n(DSCI) by the University of Nebraska Lincoln. All counties to the right of the vertical reference\n line expereinced drought, on average, over the course of the year.",
       y = "Mean Drought Severity and Coverage Index",
       x = NULL, 
       caption = "Data Source: University of Nebraska-Lincoln, 2017") +
  theme(plot.title = element_text(face="bold")) 






#air quality density ridges plot
aq_plot <- air_corn_drought %>%
  mutate(Good_days_proportion = `Good Days`/`Days with AQI`)%>%
  mutate(Moderate_days_proportion = `Moderate Days`/`Days with AQI`)%>%
  mutate(Unhealthyforsenstv_days_prop = `Unhealthy for Sensitive Groups Days`/`Days with AQI`)%>%
  mutate(Unhealthy_days_proportion = `Unhealthy Days`/`Days with AQI`)%>%
  mutate(VUnhealthy_days_proportion = `Very Unhealthy Days`/`Days with AQI`)%>%
  mutate(Hazardous_days_proportion = `Hazardous Days`/`Days with AQI`)%>%
  pivot_longer(
              cols = c("Good_days_proportion", "Moderate_days_proportion", "Unhealthyforsenstv_days_prop", "Unhealthy_days_proportion", "VUnhealthy_days_proportion", "Hazardous_days_proportion"),
               names_to = "aq_indicator",
               values_to  = "aq_days")

my_aq_factor_levels= c("Good_days_proportion", "Moderate_days_proportion", "Unhealthyforsenstv_days_prop", "Unhealthy_days_proportion", "VUnhealthy_days_proportion", "Hazardous_days_proportion")

my_aq_factor_labels <- c("Good", "Moderate", "Unhealthy for Sensitive People", "Unhealthy", 
                         "Very Unhealthy", "Hazardous")

aq_plot$aq_indicator<-factor(aq_plot$aq_indicator, levels = my_aq_factor_levels, labels = my_aq_factor_labels)

aqi_plot<-aq_plot %>%
  ggplot(aes(x = aq_days, y = fct_rev(aq_indicator), group = aq_indicator, fill = aq_indicator))+
  geom_density_ridges(alpha = .6, show.legend = FALSE, color = NA) +
  facet_wrap(~state)+
  theme_minimal()+
  scale_fill_brewer(palette = "BrBG", direction=-1)+
  scale_x_continuous(limits = c(-1.5, 1.5))+
  labs(title = "Most states in our sample experience, on average, Good or Moderate air quality.",
       subtitle = "Air quality categories are set by the Environemntal Protection Agency (EPA). Values shown are the proportion of days measured which fall into each\ncategory for the year 2017.",
    y = "Air Quality Categories",
       x = "Proportion of Measured Days", 
    caption = "Data Source: Environmental Protection Agency, 2017")+
    theme(plot.title = element_text(face="bold")) 




#corn yield map
#State corn data
state_harvest<-air_corn_drought%>%
  group_by(state)%>%
  summarise_at(vars(Quantity_Harvested),
               list(harvest_total=sum))
state_abb<-as_tibble(state.abb)%>%
  rename(state=value)
state_harvest<-left_join(state_harvest, state_abb,by="state")

state_corn_map<-
  plot_usmap(regions = "states",
             data = state_harvest,
             values = "harvest_total",
             color = "black",
             size=0.001)+
  scale_fill_gradient2(low="#F7E594",
                       mid="#F7E594",
                       high="red",
                       na.value="white",
                       name = "Bushels of corn",
                       label = scales::comma)+
  labs(title="Corn Harvest  in the United States", 
       subtitle = "Corn harvest is measured in bushels, and is aggregated by county to the state level, for the year 2017.",
       caption = "Data Source: United States Department of Agriculture, 2017 Census")+
  theme(legend.position = "right",
        panel.background=element_rect(colour = "black", fill = "white"), 
        plot.title = element_text(face="bold"))




#drought map
drought_2017<-drought%>%
  group_by(State)%>%
  summarise_at(vars(meanDSCI2017),
               list(average_DSCI=mean))%>%
  rename(state = State)
drought_2017<-left_join(drought_2017, state_abb, by = "state")

state_drought_map<-
  plot_usmap(regions = "states",
             data = drought_2017,
             values = "average_DSCI",
             color = "black",
             size=0.001)+
  scale_fill_gradient2(low="white",
                       high="dark red",
                       na.value="grey",
                       name = "Drought Index\nAnnual Average",
                       label = scales::comma)+
  labs(title="Drought Index Averages in the United States",
       subtitle = "Drought index values have been averaged over all measurements for 2017\nfor each county, and aggregated to the state level.",
       caption = "Data Source: University of Nebraska-Lincoln, 2017,")+
  theme(legend.position = "right",
        panel.background=element_rect(colour = "black", fill = "white"), 
        plot.title = element_text(face="bold"))




#air quality map 
state_aq<-air_quality%>%
  group_by(State)%>%
  summarise_at(vars(`Unhealthy Days`),
               list(average_aq=mean))%>%
  rename(state_name=State)
state_fips_aq <- fips_codes %>%
  select(c("state_name","state"))
  
state_aq <- left_join(state_aq,state_fips_aq,by="state_name")

state_aq_map<-
  plot_usmap(regions = "states",
             data = state_aq,
             values = "average_aq",
             color = "black",
             size=0.001)+
  scale_fill_gradient2(low="#F7E594",
                       mid="#F7E594",
                       high="red",
                       na.value="white",
                       name = "Average Number of Days",
                       label = scales::comma)+
  labs(title="Average Number of Days per State with Unhealthy Air Quality", 
       subtitle = "Unhealthy Air Quality is defined by the EPA as 'Everyone may begin to experience some adverse health\neffects, and members of the sensitive groups may experience more serious effects'. Map shows average\nnumber of days with unhealthy air quality across counties in each state.",
       caption = "Data Source: Environmental Protection Agency, 2017")+
  theme(legend.position = "right",
        panel.background=element_rect(colour = "black", fill = "white"), 
        plot.title = element_text(face="bold"))

```

### Corn production:
**Top 10 Corn States in 2017 and a Map of State Corn Production Totals**
```{r, fig.width = 13, fig.height= 8}
#| column: page
state_corn_map + corn_plot
```
These two visualizations help us better understand corn production across the United States. There are some regions that we found produce no corn, such as the small states in the Northeast and Southwest, where the climate is not friendly to such field crops. Further, there are some states such as Iowa that produce very large quantities of corn, especially relative to their land size. This tells us that there are clearly geographic regions of the United States that are best suited to corn production. Despite the much greater size of states such as California and Texas, there is clearly something about the climate and geography of states such as Iowa that serve as better land for corn crops. This is exciting for us because perhaps these differences can be estimated up with our drought and air quality data.
Although our data is a county-level dataset, we believe that the state-based visualizations are more productive to understanding general trends in corn production as well as drought and air quality. Droughts and poor air quality measures do not themselves stop at county lines, so differentiating between counties is neither productive to our understanding of trends nor is visually clear.

### Drought Severity and Coverage:
**Drought Dispersion in 2017 and a Map of Drought Categories**
```{r, fig.width = 13, fig.height= 8}
#| column: page
state_drought_map + drought_plot
```
As mentioned in the data section of this project, a higher drought index value is representative of more severe drought. Surprisingly, states with high corn yield actually do not have the lowest drought indeces for 2017. This could mean that there is more to crop production than precipitation levels, or lack thereof. This should be interesting in our model, as drought does not have a clear relationship with corn production, solely based on these visualizations.

### Air quality:
**Air Quality in 2017 and a Map of Air Quality by States, Measured by Unhealthy Days**
```{r}
state_aq_map 
```
As we can see through both of these visualizations, there are a few states with particularly poor air quality, especially in the West. However, eastward from the Rocky Mountains, there is very little variation in the number of days with unhealthy air quality.
```{r, fig.width = 12, fig.height= 8}
#| column: page
aqi_plot 
```
However, this is just one measure of overall air quality, and perhaps we will find in our model that there are other measures of air quality, such as days with detected Ozone, that have a stronger predictive impact on corn production.
 
## *Model and Variable Importance*
**Models**

We wanted to test out multiple models and hyperparameter tuning to make the most out of our limited dataset. We also knew that we wanted to use supervised machine learning techniques so we could  predict crop outputs. We decided to use a Lasso model and a Random Forest model. 

The Lasso model performs variable selection and regularization to target accuracy, which is very useful for a shallow dataset like ours. It also has the capability to force the coefficient (or impact) of certain variables to zero- which drops them from the model. This was useful to us as we were not certain whether some variables were useful at all in predicting crop production, and did not want them to lead to avoidably inaccurate predictions.

The Random Forest model was chosen as it was also useful for a shallow dataset. This model uses ensemble learning and regression to construct many trees and present the average prediction of these individual trees. This was also useful as we could understand variable importance with this model. 

The models are as follows: 
```{r}
set.seed(835555635)

#splitting the data
split <- initial_split(air_corn_drought, prop = .75, strata = "log_quantityharvested")
corn_train <- training(split)
corn_test <- testing(split)

#creating the recipe
corn_recipe <- recipe(log_quantityharvested ~., data = corn_train)%>%
  step_rm(all_nominal_predictors())%>%
  step_rm("Year")%>%
  step_rm("Quantity_Harvested")%>%
  step_normalize(all_numeric_predictors())%>%
  prep()

#baking the recipe
corn_baked <- bake(corn_recipe, new_data = corn_train)

#setting up v-fold cross validation
set.seed(923809584)
folds <- vfold_cv(corn_train, v=10)

#creating models
#random forest
forest_model <- rand_forest()%>%
  set_engine("ranger", importance = "impurity")%>%
  set_mode("regression")

#lasso
lasso_grid <- grid_regular(penalty(), levels = 10)
lasso_model <- linear_reg(penalty = tune(), mixture = 1)%>%
  set_engine("glmnet")%>%
  set_mode("regression")

corn_forest_wkflw <- workflow()%>%
  add_recipe(corn_recipe)%>%
  add_model(forest_model)

corn_lasso_wkflw <- workflow()%>%
  add_recipe(corn_recipe)%>%
  add_model(lasso_model)

corn_forest_cv <- corn_forest_wkflw %>%
  fit_resamples(
    resamples=folds)

corn_lasso_cv <- corn_lasso_wkflw %>%
  tune_grid(resamples = folds, 
            grid = lasso_grid)

#viewing metrics from models
lasso_metrics <- collect_metrics(corn_lasso_cv, summarize = FALSE) %>%
  filter(.metric == "rmse")%>%
  group_by(id) %>%
  summarize(rmse = mean(.estimate))

forest_metrics <- collect_metrics(corn_forest_cv, summarize = FALSE)%>%
  filter(.metric == "rmse")%>%
  rename(rmse = .estimate)

combined_metrics <- bind_rows(
  `lasso` = lasso_metrics, 
  `rforest` = forest_metrics, 
  .id = "models") %>%
  select(-c(".metric", ".estimator", ".config"))
```

### Evaluating Our Model:

**Root Mean Squared Error (RMSE)**

We used the 'collect metrics' function to collect the Root Mean Square Error(RMSE) for both the models across the 10 folds. We then combine the two metrics and plot the RMSE values. The plot shows that the Random Forest model performs better than the Lasso Regression model across all folds. This is because compared to single classification models, Random Forest reduces variance by averaging predicted probabilities across multiple trees. It uses a ransom sample from the training data for each tree and generates splits, preventing over-fitting the data. It also isolates outliers in separate leaves.

```{r}
#RMSE plot 
combined_metrics%>%
 ggplot(aes(x=id, y = rmse, group = models, color = models)) +
  geom_point()+
  geom_line()+
  theme_minimal()+
  scale_color_manual(values = c("#00AFB5", "#BD3367"), labels = c("LASSO", "Random Forest"), name = "Model")+
  labs(title = "Root Mean Squared Error (RMSE) for LASSO and Random Forest Models",
       subtitle = "Plot shows RMSE for models predicting corn yield across 10 v-fold cross validation samples. \nThe random forest model generates lower RMSEs across all folds.",
       x=NULL, 
       y = "RMSE") +
  theme(plot.title = element_text(face="bold"))
```

**Finalizing Our Model**

We finalize our model by choosing the random forest model with the lowest RMSE. We then fit this finalized model on all of our training data as well as use this model to generate predictions on our testing data. This is the final step of our supervised machine learning development.

```{r}
#finalizing model based on lowest rmse
final_model <- corn_forest_cv %>%
  select_best(metric = "rmse")

final_workflow <- finalize_workflow(corn_forest_wkflw,
                                    parameters=final_model)

corn_final_fit<-final_workflow%>%
           fit(data=corn_train)

#Predicting on testing data
corn_predictions_testing<-bind_cols(corn_test,
                      predict(object=corn_final_fit,
                              new_data=corn_test))
```

Once we run our model on our testing data, we generate metrics on how our model performed on this "new" data that it has not been tested on before. We see that our model generates an RMSE of .988. This value is not as low as we would have liked, as our maximum value for the log of quantity of corn harvested in the testing data is 7.69, with a mean of 5.9.

```{r}
metrics(corn_predictions_testing, truth = log_quantityharvested, estimate = .pred)
```

**Variable Importance**

Finally, based on our results, we visualize variable importance for the Random Forest model to see which variables in our data set play the most important role in predicting the outcome i.e. corn yield.

```{r}
corn_final_fit %>%
 extract_fit_parsnip() %>%
 vip(num_features = 10,
         aesthetics = list(fill = "cadetblue3", size = 2))+
  labs(title = "Most important variables in our model.",
subtitle = "This plot shows the variables in our data based on their importance in predicting\ncorn yield with our model.",
y = "Importance",
x = "Variables")+
  scale_x_discrete(labels= c("meanDSCI2016"="Mean DSCI in 2016", "meanDSCI2017"="Mean DSCI in 2017"))+
  theme_minimal()+
theme(plot.title = element_text(face="bold"))
```

The plot shows that mean Drought Severity and Coverage Index for 2016 and 2017 were the most important predictors in our model which is understandable considering drought levels effect crop yields. These are followed by air quality variables that measure good Air Quality Index days, days with highest AQI and moderate air quality days. Ozone concentration days, 90th percentile AQI, median AQI are also important predictors in our model but they show a lower importance. Conceptually, it makes sense that drought levels and Air Quality Index are the most important variables in predicting corn yield, as these variables affect the crops most directly throughout their growth cycle. Other metrics that we use to predict corn yields which have lower levels of importance, like the number of days which are "Unhealthy" or "Hazardous" are relatively infrequent in our data, which also could explain their low explanatory power, as these variables have little variance for the model to exploit. Finally, worse air quality current is concentrated in more urban areas, and therefore may have a lesser effect on crop production at this point in time, although the increase of air pollution events, like forest fires or increasing urban sprawl, could increase the importance of these variables in the future.

## *Conclusion and Looking Forward*

After data retrieval, cleaning, and merging, one of the more challenging aspects of this project was ultimately deciding which sorts of supervised machine learning models could work with the limited dataset we finalized. As demonstrated in the model section, we ultimately decided upon comparing a Lasso and a Random Forest model. After comparing the models on the basis of root mean square error, it was clear the random forest model better suited our data. However, it is also still clear that this random forest model is not perfect. As noted multiple times throughout this project, county-level data is quite hard to come by in the agricultural world. There are limited pools of data to use as predictors, and when measures exist, they are often not available for every county. When it came down to it, despite there being over 3,000 counties in the United States, we had a very short and a very narrow dataset of just over 600 observations. However, we made the most out of these limitations by using cross-validation to test different models and hyperparameter tuning. Although our models did not necessarily succeed in accuracy or precision, we still had an opportunity to see which variables were most useful in predicting corn production on the county level. It is exciting to know that even very limited data could potentially be used to predict crop production.
We believe we could make this model even better if we had the time and the access to more data. We would like to include many more measures of climate and environmental health as well as technology usage, which definitely impact crop production. If these data were available to us publicly and on the county-level, we could have improved our predictive model simply through access to more predictors. We searched high and low for county-level public data on temperature, precipitation, weather events, soil health, soil pH, soil moisture, soil type, air humidity, fertilizer use, pesticide use, availability of genetically modified seeds, and many others. Despite these limitations in our own project, we believe that strengthening the model is possible. However, we do not believe that the average farm operator would have access to all this information. If she could use a model like ours to better predict her crop output, she may be able to adapt to other more useful technologies and farming techniques to make the most of her land, despite the negative impacts of climate change making the environment much more unpredictable.
